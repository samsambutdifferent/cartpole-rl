{"cells":[{"cell_type":"markdown","metadata":{"id":"aLkT46rqhwUB"},"source":["## Configurations for Colab"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44076,"status":"ok","timestamp":1660769348003,"user":{"displayName":"Suemayah Eldursi","userId":"17062391200158734824"},"user_tz":-60},"id":"92WZWAmshwUC","outputId":"dca6a247-6eec-40ed-e577-efb9d8d74c95"},"outputs":[{"name":"stdout","output_type":"stream","text":["The operation couldn’t be completed. Unable to locate a Java Runtime.\n","Please visit http://www.java.com for information on installing Java.\n","\n","zsh:1: no matches found: gym[box2d,atari,accept-rom-license]\n","Note: you may need to restart the kernel to use updated packages.\n","Defaulting to user installation because normal site-packages is not writeable\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torch (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for torch\u001b[0m\n","\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.2.2 is available.\n","You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["import sys\n","\n","if \"google.colab\" in sys.modules:\n","    !apt install python-opengl\n","    !apt install ffmpeg\n","    !apt install xvfb\n","    !pip install PyVirtualDisplay==3.0\n","    !pip install gym==0.21.0\n","    %pip install -U gym[box2d,atari,accept-rom-license]\n","else: \n","    !apt update &&  sudo apt-get install ffmpeg libsm6 libxext6  -y\n","    %pip install -U gym[box2d,atari,accept-rom-license]\n","\n","%pip install torch matplotlib gym==0.21.0 PyVirtualDisplay==3.0\n","\n","# from pyvirtualdisplay import Display\n","\n","# dis = Display(visible=0, size=(400, 400))\n","# dis.start()"]},{"cell_type":"markdown","metadata":{"id":"sxr4tvFnhwUC"},"source":["# 01. DQN\n","\n","[V. Mnih et al., \"Human-level control through deep reinforcement learning.\" Nature, 518\n","(7540):529–533, 2015.](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf)\n","\n","Reinforcement learning is known to be unstable or even to diverge when a nonlinear function approximator such as a neural network is used to represent the action-value (also known as $Q$) function. This instability has several causes: the correlations present in the sequence of observations, the fact that small updates to $Q$ may significantly change the policy and therefore change the data distribution, and the correlations between the action-values ($Q$) and the target values $r + \\gamma \\max_{a'} Q(s', a')$.\n","\n","The authors suggest two key ideas to address these instabilities with a novel variant of Q-learning: Replay buffer and Fixed Q-target.\n","\n","#### Uniformly random sampling from Experience Replay Memory\n","\n","Reinforcement learning agent stores the experiences consecutively in the buffer, so adjacent ($s, a, r, s'$) transitions stored are highly likely to have correlation. To remove this, the agent samples experiences uniformly at random from the pool of stored samples $\\big( (s, a, r, s') \\sim U(D) \\big)$. See sample_batch method of ReplayBuffer class for more details.\n","\n","#### Fixed Q-target\n","\n","DQN uses an iterative update that adjusts the action-values ($Q$) towards target values that are only periodically updated, thereby reducing correlations with the target; if not, it is easily divergy because the target continuously moves. The Q-learning update at iteration $i$ uses the following loss function:\n","\n","$$\n","L_i(\\theta_i) = \\mathbb{E}_{(s,a,r,s') \\sim U(D)} \\big[ \\big( r + \\gamma \\max_{a'} Q(s',a';\\theta_i^-) - Q(s, a; \\theta_i) \\big)^2 \\big]\n","$$\n","\n","in which $\\gamma$ is the discount factor determining the agent’s horizon, $\\theta_i$ are the parameters of the Q-network at iteration $i$ and $\\theta_i^-$ are the network parameters used to compute the target at iteration $i$. The target network parameters $\\theta_i^-$ are only updated with the Q-network parameters ($\\theta_i$) every C steps and are held fixed between individual updates. ($C = 200$ in CartPole-v0)\n","\n","#### For more stability: Gradient clipping\n","\n","The authors also found it helpful to clip the error term from the update $r + \\gamma \\max_{a'} Q(s', a'; \\theta_i^-) - Q(s,a,;\\theta_i)$ to be between -1 and 1. Because the absolute value loss function $|x|$ has a derivative of -1 for all negative values of x and a derivative of 1 for all positive values of x, clipping the squared error to be between -1 and 1 corresponds to using an absolute value loss function for errors outside of the (-1,1) interval. This form of error clipping further improved the stability of the algorithm."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2904,"status":"ok","timestamp":1660769350901,"user":{"displayName":"Suemayah Eldursi","userId":"17062391200158734824"},"user_tz":-60},"id":"bBsOlEDBhwUC"},"outputs":[],"source":["import os\n","from typing import Dict, List, Tuple\n","\n","import gym\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from IPython.display import clear_output"]},{"cell_type":"markdown","metadata":{"id":"7Fx9Me93hwUD"},"source":["## Replay buffer\n","\n","Typically, people implement replay buffers with one of the following three data structures:\n","\n","  - collections.deque\n","  - list\n","  - numpy.ndarray\n","  \n","**deque** is very easy to handle once you initialize its maximum length (e.g. deque(maxlen=buffer_size)). However, the indexing operation of deque gets terribly slow as it grows up because it is [internally doubly linked list](https://wiki.python.org/moin/TimeComplexity#collections.deque). On the other hands, **list** is an array, so it is relatively faster than deque when you sample batches at every step. Its amortized cost of  *Get item* is [O(1)](https://wiki.python.org/moin/TimeComplexity#list).\n","\n","Last but not least, let's see **numpy.ndarray**. numpy.ndarray is even faster than list due to the fact that it is [a homogeneous array of fixed-size items](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray), so you can get the benefits of [locality of reference](https://en.wikipedia.org/wiki/Locality_of_reference). Whereas list is an array of pointers to objects, even when all of them are of the same type.\n","\n","Here, we are going to implement a replay buffer using numpy.ndarray.\n","\n","\n","Reference: [OpenAI spinning-up](https://github.com/openai/spinningup/blob/master/spinup/algos/sac/sac.py#L10)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1660769350902,"user":{"displayName":"Suemayah Eldursi","userId":"17062391200158734824"},"user_tz":-60},"id":"NUmYf3ZUhwUD"},"outputs":[],"source":["class ReplayBuffer:\n","    \"\"\"A simple numpy replay buffer.\"\"\"\n","\n","    def __init__(self, obs_dim: int, size: int, batch_size: int = 32):\n","        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n","        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n","        self.acts_buf = np.zeros([size], dtype=np.float32)\n","        self.rews_buf = np.zeros([size], dtype=np.float32)\n","        self.done_buf = np.zeros(size, dtype=np.float32)\n","        self.max_size, self.batch_size = size, batch_size\n","        self.ptr, self.size, = 0, 0\n","\n","    def store(\n","        self,\n","        obs: np.ndarray,\n","        act: np.ndarray, \n","        rew: float, \n","        next_obs: np.ndarray, \n","        done: bool,\n","    ):\n","        self.obs_buf[self.ptr] = obs\n","        self.next_obs_buf[self.ptr] = next_obs\n","        self.acts_buf[self.ptr] = act\n","        self.rews_buf[self.ptr] = rew\n","        self.done_buf[self.ptr] = done\n","        self.ptr = (self.ptr + 1) % self.max_size\n","        self.size = min(self.size + 1, self.max_size)\n","\n","    def sample_batch(self) -> Dict[str, np.ndarray]:\n","        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n","        return dict(obs=self.obs_buf[idxs],\n","                    next_obs=self.next_obs_buf[idxs],\n","                    acts=self.acts_buf[idxs],\n","                    rews=self.rews_buf[idxs],\n","                    done=self.done_buf[idxs])\n","\n","    def __len__(self) -> int:\n","        return self.size"]},{"cell_type":"markdown","metadata":{"id":"Ra18UwLbhwUD"},"source":["## Network\n","\n","We are going to use a simple network architecture with three fully connected layers and two non-linearity functions (ReLU)."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1660769350903,"user":{"displayName":"Suemayah Eldursi","userId":"17062391200158734824"},"user_tz":-60},"id":"xMaFntXqhwUD"},"outputs":[],"source":["class Network(nn.Module):\n","    def __init__(self, in_dim: int, out_dim: int):\n","        \"\"\"Initialization.\"\"\"\n","        super(Network, self).__init__()\n","\n","        self.layers = nn.Sequential(\n","            nn.Linear(in_dim, 128), \n","            nn.ReLU(),\n","            nn.Linear(128, 128), \n","            nn.ReLU(), \n","            nn.Linear(128, out_dim)\n","        )\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        \"\"\"Forward method implementation.\"\"\"\n","        return self.layers(x)"]},{"cell_type":"markdown","metadata":{"id":"0ieCePeqhwUD"},"source":["## DQN Agent\n","\n","Here is a summary of DQNAgent class.\n","\n","| Method           | Note                                                 |\n","| ---              | ---                                                  |\n","|select_action     | select an action from the input state.               |\n","|step              | take an action and return the response of the env.   |\n","|compute_dqn_loss  | return dqn loss.                                     |\n","|update_model      | update the model by gradient descent.                |\n","|target_hard_update| hard update from the local model to the target model.|\n","|train             | train the agent during num_frames.                   |\n","|test              | test the agent (1 episode).                          |\n","|plot              | plot the training progresses.                        |\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1660769580151,"user":{"displayName":"Suemayah Eldursi","userId":"17062391200158734824"},"user_tz":-60},"id":"kDNb4rwihwUD"},"outputs":[],"source":["class DQNAgent:\n","    \"\"\"DQN Agent interacting with environment.\n","    \n","    Attribute:\n","        env (gym.Env): openAI Gym environment\n","        memory (ReplayBuffer): replay memory to store transitions\n","        batch_size (int): batch size for sampling\n","        epsilon (float): parameter for epsilon greedy policy\n","        epsilon_decay (float): step size to decrease epsilon\n","        max_epsilon (float): max value of epsilon\n","        min_epsilon (float): min value of epsilon\n","        target_update (int): period for target model's hard update\n","        gamma (float): discount factor\n","        dqn (Network): model to train and select actions\n","        dqn_target (Network): target model to update\n","        optimizer (torch.optim): optimizer for training dqn\n","        transition (list): transition information including \n","                           state, action, reward, next_state, done\n","    \"\"\"\n","\n","    def __init__(\n","        self, \n","        env: gym.Env,\n","        memory_size: int,\n","        batch_size: int,\n","        target_update: int,\n","        epsilon_decay: float,\n","        max_epsilon: float = 1.0,\n","        min_epsilon: float = 0.1,\n","        gamma: float = 0.99,\n","    ):\n","        \"\"\"Initialization.\n","        \n","        Args:\n","            env (gym.Env): openAI Gym environment\n","            memory_size (int): length of memory\n","            batch_size (int): batch size for sampling\n","            target_update (int): period for target model's hard update\n","            epsilon_decay (float): step size to decrease epsilon\n","            lr (float): learning rate\n","            max_epsilon (float): max value of epsilon\n","            min_epsilon (float): min value of epsilon\n","            gamma (float): discount factor\n","        \"\"\"\n","        obs_dim = env.observation_space.shape[0]\n","        action_dim = env.action_space.n\n","        \n","        self.env = env\n","        self.memory = ReplayBuffer(obs_dim, memory_size, batch_size)\n","        self.batch_size = batch_size\n","        self.epsilon = max_epsilon\n","        self.epsilon_decay = epsilon_decay\n","        self.max_epsilon = max_epsilon\n","        self.min_epsilon = min_epsilon\n","        self.target_update = target_update\n","        self.gamma = gamma\n","        \n","        # device: cpu / gpu\n","        self.device = torch.device(\n","            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","        )\n","        print(self.device)\n","\n","        # networks: dqn, dqn_target\n","        self.dqn = Network(obs_dim, action_dim).to(self.device)\n","        self.dqn_target = Network(obs_dim, action_dim).to(self.device)\n","        self.dqn_target.load_state_dict(self.dqn.state_dict())\n","        self.dqn_target.eval()\n","        \n","        # optimizer\n","        self.optimizer = optim.Adam(self.dqn.parameters())\n","\n","        # transition to store in memory\n","        self.transition = list()\n","        \n","        # mode: train / test\n","        self.is_test = False\n","\n","    def select_action(self, state: np.ndarray) -> np.ndarray:\n","        \"\"\"Select an action from the input state.\"\"\"\n","        # epsilon greedy policy\n","        if self.epsilon > np.random.random():\n","            selected_action = self.env.action_space.sample()\n","        else:\n","            selected_action = self.dqn(\n","                torch.FloatTensor(state).to(self.device)\n","            ).argmax()\n","            selected_action = selected_action.detach().cpu().numpy()\n","        \n","        if not self.is_test:\n","            self.transition = [state, selected_action]\n","        \n","        return selected_action\n","\n","    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n","        \"\"\"Take an action and return the response of the env.\"\"\"\n","        next_state, reward, done, _ = self.env.step(action)\n","\n","        if not self.is_test:\n","            self.transition += [reward, next_state, done]\n","            self.memory.store(*self.transition)\n","    \n","        return next_state, reward, done\n","\n","    def update_model(self) -> torch.Tensor:\n","        \"\"\"Update the model by gradient descent.\"\"\"\n","        samples = self.memory.sample_batch()\n","\n","        loss = self._compute_dqn_loss(samples)\n","\n","        self.optimizer.zero_grad()\n","        loss.backward()\n","        self.optimizer.step()\n","\n","        return loss.item()\n","        \n","    def train(self, num_frames: int, plotting_interval: int = 200):\n","        \"\"\"Train the agent.\"\"\"\n","        self.is_test = False\n","        \n","        state = self.env.reset()\n","        update_cnt = 0\n","        epsilons = []\n","        losses = []\n","        scores = []\n","        score = 0\n","\n","        for frame_idx in range(1, num_frames + 1):\n","            action = self.select_action(state)\n","            next_state, reward, done = self.step(action)\n","\n","            state = next_state\n","            score += reward\n","\n","            # if episode ends\n","            if done:\n","                state = self.env.reset()\n","                scores.append(score)\n","                score = 0\n","\n","            # if training is ready\n","            if len(self.memory) >= self.batch_size:\n","                loss = self.update_model()\n","                losses.append(loss)\n","                update_cnt += 1\n","                \n","                # linearly decrease epsilon\n","                self.epsilon = max(\n","                    self.min_epsilon, self.epsilon - (\n","                        self.max_epsilon - self.min_epsilon\n","                    ) * self.epsilon_decay\n","                )\n","                epsilons.append(self.epsilon)\n","                \n","                # if hard update is needed\n","                if update_cnt % self.target_update == 0:\n","                    self._target_hard_update()\n","\n","            # plotting\n","            if frame_idx % plotting_interval == 0:\n","                self._plot(frame_idx, scores, losses, epsilons)\n","                \n","        self.env.close()\n","                \n","    def test(self, video_folder: str) -> None:\n","        \"\"\"Test the agent.\"\"\"\n","        self.is_test = True\n","        \n","        # for recording a video\n","        naive_env = self.env\n","        self.env = gym.wrappers.RecordVideo(self.env, video_folder=video_folder)\n","        \n","        state = self.env.reset()\n","        done = False\n","        score = 0\n","        \n","        while not done:\n","            action = self.select_action(state)\n","            next_state, reward, done = self.step(action)\n","\n","            state = next_state\n","            score += reward\n","        \n","        print(\"score: \", score)\n","        self.env.close()\n","        \n","        # reset\n","        self.env = naive_env\n","\n","    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:\n","        \"\"\"Return dqn loss.\"\"\"\n","        device = self.device  # for shortening the following lines\n","        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n","        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n","        action = torch.LongTensor(samples[\"acts\"].reshape(-1, 1)).to(device)\n","        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n","        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n","\n","        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal\n","        #       = r                       otherwise\n","        curr_q_value = self.dqn(state).gather(1, action)\n","        next_q_value = self.dqn_target(\n","            next_state\n","        ).max(dim=1, keepdim=True)[0].detach()\n","        mask = 1 - done\n","        target = (reward + self.gamma * next_q_value * mask).to(self.device)\n","\n","        # calculate dqn loss\n","        loss = F.smooth_l1_loss(curr_q_value, target)\n","\n","        return loss\n","\n","    def _target_hard_update(self):\n","        \"\"\"Hard update: target <- local.\"\"\"\n","        self.dqn_target.load_state_dict(self.dqn.state_dict())\n","                \n","    def _plot(\n","        self, \n","        frame_idx: int, \n","        scores: List[float], \n","        losses: List[float], \n","        epsilons: List[float],\n","    ):\n","        \"\"\"Plot the training progresses.\"\"\"\n","        clear_output(True)\n","        plt.figure(figsize=(20, 5))\n","        plt.subplot(131)\n","        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))\n","        plt.plot(scores)\n","        plt.subplot(132)\n","        plt.title('loss')\n","        plt.plot(losses)\n","        plt.subplot(133)\n","        plt.title('epsilons')\n","        plt.plot(epsilons)\n","        plt.show()"]},{"cell_type":"markdown","metadata":{"id":"otLYB_-whwUE"},"source":["## Environment\n","\n","You can see the [code](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py) and [configurations](https://github.com/openai/gym/blob/master/gym/envs/__init__.py#L53) of CartPole-v0 from OpenAI's repository."]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":237,"status":"ok","timestamp":1660769583755,"user":{"displayName":"Suemayah Eldursi","userId":"17062391200158734824"},"user_tz":-60},"id":"MdKyJt5KhwUE"},"outputs":[],"source":["# environment\n","env = gym.make(\"ALE/Boxing-v5\", difficulty=1)\n"]},{"cell_type":"markdown","metadata":{"id":"oLMz1BnthwUE"},"source":["## Set random seed"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":277,"status":"ok","timestamp":1660769586321,"user":{"displayName":"Suemayah Eldursi","userId":"17062391200158734824"},"user_tz":-60},"id":"lF1XctaChwUE","outputId":"079a3be1-e27d-42d9-ecf0-6cfc9bdc48dd"},"outputs":[{"data":{"text/plain":["(981238343, 1920203758)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["seed = 777\n","\n","def seed_torch(seed):\n","    torch.manual_seed(seed)\n","    if torch.backends.cudnn.enabled:\n","        torch.backends.cudnn.benchmark = False\n","        torch.backends.cudnn.deterministic = True\n","\n","np.random.seed(seed)\n","seed_torch(seed)\n","env.seed(seed)"]},{"cell_type":"markdown","metadata":{"id":"ls1c_itZhwUF"},"source":["## Initialize"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353},"executionInfo":{"elapsed":296,"status":"error","timestamp":1660769588094,"user":{"displayName":"Suemayah Eldursi","userId":"17062391200158734824"},"user_tz":-60},"id":"qcW3_naUhwUF","outputId":"6b1f65ba-e83f-4704-8e22-2553699fbcb2"},"outputs":[{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-c533574dff8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mepsilon_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQNAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_update\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-57a9fa15704f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env, memory_size, batch_size, target_update, epsilon_decay, max_epsilon, min_epsilon, gamma)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReplayBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-729490adc424>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obs_dim, size, batch_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs_buf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_obs_buf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macts_buf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'tuple' object cannot be interpreted as an integer"]}],"source":["# parameters\n","num_frames = 10000\n","memory_size = 1000\n","batch_size = 32\n","target_update = 100\n","epsilon_decay = 1 / 2000\n","\n","agent = DQNAgent(env, memory_size, batch_size, target_update, epsilon_decay)"]},{"cell_type":"markdown","metadata":{"id":"vnBYU5q0hwUF"},"source":["## Train"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":318},"executionInfo":{"elapsed":260,"status":"error","timestamp":1660769366453,"user":{"displayName":"Suemayah Eldursi","userId":"17062391200158734824"},"user_tz":-60},"id":"zF8xw5n3hwUF","outputId":"995083a7-d914-45fa-f5f4-353afd5d9b50"},"outputs":[{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-4326fee8443c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-27b4763e2921>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_frames, plotting_interval)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mframe_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-27b4763e2921>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransition\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-729490adc424>\u001b[0m in \u001b[0;36mstore\u001b[0;34m(self, obs, act, rew, next_obs, done)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     ):\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs_buf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_obs_buf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_obs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macts_buf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (210,160,3) into shape (210,)"]}],"source":["agent.train(num_frames)"]},{"cell_type":"markdown","metadata":{"id":"Lxh4kW4vhwUF"},"source":["## Test\n","\n","Run the trained agent (1 episode)."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3524,"status":"ok","timestamp":1660768855907,"user":{"displayName":"Suemayah Eldursi","userId":"17062391200158734824"},"user_tz":-60},"id":"ujWwy7hzhwUF","outputId":"5d7330c7-8c7e-4c18-ee57-096e7cdf1e98"},"outputs":[{"name":"stdout","output_type":"stream","text":["score:  154.0\n"]}],"source":["video_folder=\"videos/dqn\"\n","agent.test(video_folder=video_folder)"]},{"cell_type":"markdown","metadata":{"id":"xJtg-cL6hwUF"},"source":["## Render"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1660768855908,"user":{"displayName":"Suemayah Eldursi","userId":"17062391200158734824"},"user_tz":-60},"id":"Wz0x0Gl4hwUG","outputId":"f4ab6676-119a-494c-9779-7f00851ee101"},"outputs":[{"data":{"text/html":["\n","        <video width=\"320\" height=\"240\" alt=\"test\" controls>\n","        <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\"/>\n","        </video>\n","        "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Played: videos/dqn/rl-video-episode-0.mp4\n"]}],"source":["import base64\n","import glob\n","import io\n","import os\n","\n","from IPython.display import HTML, display\n","\n","\n","def ipython_show_video(path: str) -> None:\n","    \"\"\"Show a video at `path` within IPython Notebook.\"\"\"\n","    if not os.path.isfile(path):\n","        raise NameError(\"Cannot access: {}\".format(path))\n","\n","    video = io.open(path, \"r+b\").read()\n","    encoded = base64.b64encode(video)\n","\n","    display(HTML(\n","        data=\"\"\"\n","        <video width=\"320\" height=\"240\" alt=\"test\" controls>\n","        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\"/>\n","        </video>\n","        \"\"\".format(encoded.decode(\"ascii\"))\n","    ))\n","\n","\n","def show_latest_video(video_folder: str) -> str:\n","    \"\"\"Show the most recently recorded video from video folder.\"\"\"\n","    list_of_files = glob.glob(os.path.join(video_folder, \"*.mp4\"))\n","    latest_file = max(list_of_files, key=os.path.getctime)\n","    ipython_show_video(latest_file)\n","    return latest_file\n","\n","\n","latest_file = show_latest_video(video_folder=video_folder)\n","print(\"Played:\", latest_file)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"dqn-cartpole.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.9"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":0}
